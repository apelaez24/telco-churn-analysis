
# ğŸ“Š Telco Customer Churn Analysis

**Author:** Angel Pelaez  
**Project Type:** Data Cleaning Â· Exploratory Data Analysis Â· SQL Database Integration

---

## ğŸ“Œ Project Overview

This project analyzes customer churn behavior for a fictional telecom company.  
The goal is to identify factors that contribute to churn and to build a pipeline that:
- Cleans raw customer data
- Generates key visual insights
- Stores the clean dataset in a PostgreSQL database for future analysis

---

## ğŸ“ Project Structure

â”œâ”€â”€ data/
â”‚ â””â”€â”€ telco_churn_cleaned.csv # Final cleaned dataset
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 1_data_cleaning.ipynb # Data cleaning & export CSV
â”‚ â”œâ”€â”€ 2_eda_visuals.ipynb # EDA plots & insights
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ create_tables.sql # SQL schema (optional, not needed if using Python loader)
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ load_to_postgres.py # Python script to load data to PostgreSQL
â”œâ”€â”€ .env # Database credentials (not tracked in Git)
â”œâ”€â”€ .gitignore # Ignores .env & other junk files
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ README.md # This file


---

## ğŸš€ How to Run This Project

1ï¸âƒ£ **Clone the repository**

git clone https://github.com/yourusername/telco-churn-analysis.git
cd telco-churn-analysis


2ï¸âƒ£ **Create & activate a virtual environment**

conda create -n flask_env python=3.11
conda activate flask_env


3ï¸âƒ£ **Install all required packages**

pip install -r requirements.txt


4ï¸âƒ£ **Run the Jupyter notebooks in order**

notebooks/1_data_cleaning.ipynb
ğŸ‘‰ Loads raw data, cleans it, saves telco_churn_cleaned.csv to data/.

notebooks/2_eda_visuals.ipynb
ğŸ‘‰ Loads the cleaned CSV, generates visualizations, and summarizes insights.


5ï¸âƒ£ **Load the cleaned data to PostgreSQL**

When your local PostgreSQL server is ready:

Create a .env file in the root directory with your database credentials:

POSTGRES_USER=your_postgres_username
POSTGRES_PASSWORD=your_postgres_password
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=your_database_name

Then run:
python scripts/load_to_postgres.py

This will automatically create (or replace) the telco_churn table and load the cleaned data.

## âœ… Recommended way

1ï¸âƒ£ Run `sql/create_tables.sql` once to define the table with the proper schema and constraints.

2ï¸âƒ£ Then run `python scripts/load_to_postgres.py`  
   ğŸ‘‰ This will append new rows without dropping the table.

---
## ğŸ”‘ Key Insights

âœ… Month-to-month contract customers have the highest churn rate

âœ… Customers with shorter tenure are more likely to churn

âœ… Higher monthly charges slightly increase churn risk

âœ… Senior citizens churn slightly more than non-seniors

---

## ğŸ—‚ï¸ Dependencies

All dependencies are listed in requirements.txt:

pandas

seaborn

matplotlib

SQLAlchemy

python-dotenv

and others used in notebooks

---

## ğŸ”’ Notes on Security

âš ï¸ .env is used to keep database credentials private.

This file is ignored by .gitignore and should never be pushed to GitHub.

---

